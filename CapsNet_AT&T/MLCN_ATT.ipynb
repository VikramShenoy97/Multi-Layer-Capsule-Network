{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "CapsNet.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "pycharm-6b736dc6",
   "language": "python",
   "display_name": "PyCharm (Multi-Layer-Capsule-Network)"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from make_graph import plot_graph, generate_reconstructions\n",
    "from capsnet_ATT.MLCN_ATT import CapsuleNetwork, CapsuleLoss\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "transform = transforms.Compose([transforms.Grayscale(num_output_channels=1), transforms.ToTensor()])\n",
    "# trainset = datasets.MNIST(\"MNIST_data/\", transform=transform, download=True, train=True)\n",
    "# testset = datasets.MNIST(\"MNIST_data/\", transform=transform, download=True, train=False)\n",
    "# trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "trainset = datasets.ImageFolder(\"data/faces/training/\", transform=transform)\n",
    "testset = datasets.ImageFolder(\"data/faces/testing/\", transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1, shuffle=True)\n",
    "\n",
    "model = CapsuleNetwork()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_function = CapsuleLoss()\n",
    "epochs = 50\n",
    "overall_training_accuracy = []\n",
    "overall_training_loss = []\n",
    "mode = \"Train\" # {\"Train\", \"Test\", \"VPA\"}\n",
    "\n",
    "if mode == \"Train\":\n",
    "  for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    running_loss = 0\n",
    "    training_accuracy = 0\n",
    "    count = 0\n",
    "    percent = 0\n",
    "    for images, raw_labels in iter(trainloader):\n",
    "      # print(\"Image: \", images.shape)\n",
    "      # images = torch.squeeze(images, 1)\n",
    "      count += 1\n",
    "      # Generate One Hot encodings of labels\n",
    "      labels = torch.eye(40).index_select(dim=0, index=raw_labels)\n",
    "      class_probabilities, reconstructions = model(images.to(device), labels.to(device))\n",
    "      # Compute Loss and Gradients\n",
    "      loss = loss_function(images.to(device), reconstructions, labels.to(device), class_probabilities)\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "      _, logits = class_probabilities.topk(k=1, dim=1)\n",
    "      # Calculate Accuracy\n",
    "      training_accuracy_tensor = logits.view(*raw_labels.shape) == raw_labels.to(device)\n",
    "      training_accuracy += torch.mean(training_accuracy_tensor.type(torch.FloatTensor))\n",
    "      if(count % (int(len(trainloader)/10)+1) == 0):\n",
    "        percent += 10\n",
    "        print(\"%d %% Complete\" % (percent))\n",
    "    percent += 10\n",
    "    print(\"%d %% Complete\" % (percent))\n",
    "    training_loss = running_loss / len(trainloader)\n",
    "    training_accuracy = training_accuracy * 100 / len(trainloader)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Epoch %d / %d:\" % (epoch+1, epochs))\n",
    "    print(\"Time Elapsed = %d s\" % (elapsed_time))\n",
    "    print(\"Training Loss = %f\" % (training_loss))\n",
    "    print(\"Training Accuracy = %0.2f %%\" % (training_accuracy))\n",
    "    if ((epoch+1) % 10 == 0):\n",
    "      print(\"Generate Reconstructions:\")\n",
    "      generate_reconstructions(reconstructions[0].cpu(), images[0].cpu(), epoch+1)\n",
    "      print(\"Reconstructions Generated\")\n",
    "    overall_training_accuracy.append(training_accuracy)\n",
    "    overall_training_loss.append(training_loss)\n",
    "    history = {\n",
    "      \"train_loss\": overall_training_loss,\n",
    "      \"train_accuracy\": overall_training_accuracy\n",
    "    }\n",
    "  np.save(\"history.npy\", history)\n",
    "  torch.save(model, \"model.pth\")\n",
    "\n",
    "elif mode == \"Test\":\n",
    "  # Testing\n",
    "  testloader = torch.utils.data.DataLoader(testset, shuffle=True, batch_size=100)\n",
    "  loaded_model = torch.load(\"model.pth\")\n",
    "  loaded_model.to(device)\n",
    "  loaded_model.eval()\n",
    "  testing_accuracy = 0\n",
    "\n",
    "  for images, labels in iter(testloader):\n",
    "      class_probabilities, reconstructions = loaded_model(images.to(device))\n",
    "      _, logits = class_probabilities.topk(k=1, dim=1)\n",
    "      testing_accuracy_tensor = logits.view(*labels.shape) == labels.to(device)\n",
    "      testing_accuracy += torch.mean(testing_accuracy_tensor.type(torch.FloatTensor))\n",
    "  testing_accuracy = testing_accuracy * 100 / len(testloader)\n",
    "  print(\"Test Accuracy = %0.2f %%\" % (testing_accuracy))\n",
    "  generate_reconstructions(reconstructions.cpu(), images.cpu(), \"Test\")\n",
    "  plot_graph(testing_accuracy)\n",
    "\n",
    "elif mode == \"VPA\":\n",
    "  # Vector Perturbation Analysis\n",
    "  loaded_model = torch.load(\"model.pth\")\n",
    "  loaded_model.eval()\n",
    "  test_indices = list(range(0, 11))\n",
    "  # Create a batch size of 11\n",
    "  test_sampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
    "  testloader = torch.utils.data.DataLoader(testset, sampler=test_sampler, batch_size=11)\n",
    "  # Vector Perturbation Analysis\n",
    "  for images, _ in iter(testloader):\n",
    "    _, reconstructions = loaded_model(images.to(device), pose=True)\n",
    "  generate_reconstructions(reconstructions.cpu())\n",
    "\n",
    "  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ]
}