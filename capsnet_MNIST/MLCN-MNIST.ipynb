{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "CapsNet.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "accelerator": "GPU",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from capsnet_MNIST.make_graph import plot_graph, generate_reconstructions, generate_encoding_graph\n",
    "from capsnet_MNIST.MLCN import CapsuleNetwork, CapsuleLoss\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "model_name = \"./Harry50/model.pth\"\n",
    "device = 'cuda'\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = datasets.MNIST(\"MNIST_data/\", transform=transform, download=True, train=True)\n",
    "testset = datasets.MNIST(\"MNIST_data/\", transform=transform, download=True, train=False)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "\n",
    "model = CapsuleNetwork()\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_function = CapsuleLoss()\n",
    "epochs = 100\n",
    "epoch_interval = [25, 50, 75, 100]\n",
    "overall_training_accuracy = []\n",
    "overall_training_loss = []\n",
    "mode = \"Test\" # {\"Train\", \"Test\", \"VPA\", \"LVG\"}\n",
    "\n",
    "if mode == \"Train\":\n",
    "  for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    running_loss = 0\n",
    "    training_accuracy = 0\n",
    "    count = 0\n",
    "    percent = 0\n",
    "    for images, raw_labels in iter(trainloader):\n",
    "      count += 1\n",
    "      # Generate One Hot encodings of labels\n",
    "      labels = torch.eye(10).index_select(dim=0, index=raw_labels)\n",
    "      class_probabilities, reconstructions = model(images.to(device), labels.to(device))\n",
    "      # Compute Loss and Gradients\n",
    "      loss = loss_function(images.to(device), reconstructions, labels.to(device), class_probabilities)\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "      _, logits = class_probabilities.topk(k=1, dim=1)\n",
    "      # Calculate Accuracy\n",
    "      training_accuracy_tensor = logits.view(*raw_labels.shape) == raw_labels.to(device)\n",
    "      training_accuracy += torch.mean(training_accuracy_tensor.type(torch.FloatTensor))\n",
    "      if(count % (int(len(trainloader)/10)+1) == 0):\n",
    "        percent += 10\n",
    "        print(\"%d %% Complete\" % (percent))\n",
    "    percent += 10\n",
    "    print(\"%d %% Complete\" % (percent))\n",
    "    training_loss = running_loss / len(trainloader)\n",
    "    training_accuracy = training_accuracy * 100 / len(trainloader)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(\"Epoch %d / %d:\" % (epoch+1, epochs))\n",
    "    print(\"Time Elapsed = %d s\" % (elapsed_time))\n",
    "    print(\"Training Loss = %f\" % (training_loss))\n",
    "    print(\"Training Accuracy = %0.2f %%\" % (training_accuracy))\n",
    "    if ((epoch+1) % 10 == 0):\n",
    "      print(\"Generate Reconstructions:\")\n",
    "      generate_reconstructions(reconstructions[:10].cpu(), images[:10].cpu(), epoch+1)\n",
    "      print(\"Reconstructions Generated\")\n",
    "    overall_training_accuracy.append(training_accuracy)\n",
    "    overall_training_loss.append(training_loss)\n",
    "    history = {\n",
    "      \"train_loss\": overall_training_loss,\n",
    "      \"train_accuracy\": overall_training_accuracy\n",
    "    }\n",
    "    if((epoch+1) in epoch_interval):\n",
    "      np.save(\"history.npy\", history)\n",
    "      torch.save(model, model_name) \n",
    "\n",
    "elif mode == \"Test\":\n",
    "  # Testing\n",
    "  testloader = torch.utils.data.DataLoader(testset, shuffle=True, batch_size=100)\n",
    "  loaded_model = torch.load(model_name)\n",
    "  loaded_model.to(device)\n",
    "  loaded_model.eval()\n",
    "  testing_accuracy = 0\n",
    "\n",
    "  for images, labels in iter(testloader):\n",
    "      class_probabilities, reconstructions = loaded_model(images.to(device))\n",
    "      _, logits = class_probabilities.topk(k=1, dim=1)\n",
    "      testing_accuracy_tensor = logits.view(*labels.shape) == labels.to(device)\n",
    "      testing_accuracy += torch.mean(testing_accuracy_tensor.type(torch.FloatTensor))\n",
    "  testing_accuracy = testing_accuracy * 100 / len(testloader)                                   \n",
    "  print(\"Test Accuracy = %0.2f %%\" % (testing_accuracy))                           \n",
    "  generate_reconstructions(reconstructions.cpu(), images.cpu(), \"Test\")\n",
    "  plot_graph(testing_accuracy)\n",
    "\n",
    "elif mode == \"VPA\":\n",
    "  # Vector Perturbation Analysis\n",
    "  loaded_model = torch.load(model_name)\n",
    "  loaded_model.eval()\n",
    "  test_indices = list(range(0, 11))\n",
    "  # Create a batch size of 11\n",
    "  test_sampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
    "  testloader = torch.utils.data.DataLoader(testset, sampler=test_sampler, batch_size=11)\n",
    "  # Vector Perturbation Analysis\n",
    "  for images, _ in iter(testloader):\n",
    "    _, reconstructions = loaded_model(images.to(device), pose=True)\n",
    "  generate_reconstructions(reconstructions.cpu())\n",
    "\n",
    "elif mode == \"LVG\":\n",
    "  # Latent Vector Generations\n",
    "  loaded_model = torch.load(model_name)\n",
    "  loaded_model.eval()\n",
    "  subset_size = 100\n",
    "  analysis_epochs = 10\n",
    "  test_indices = list(range(0, subset_size))\n",
    "  for epoch in range(0, analysis_epochs):\n",
    "    # Create a batch size of Subset Size\n",
    "    test_sampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
    "    testloader = torch.utils.data.DataLoader(testset, sampler=test_sampler, batch_size=subset_size)\n",
    "    # Generate Encodings\n",
    "    for images, labels in iter(testloader):\n",
    "      encodings = loaded_model(images.to(device), encodings=True)\n",
    "    encodings = encodings.reshape(encodings.shape[0], -1)\n",
    "    cosine_similarity = nn.CosineSimilarity(dim=-1)\n",
    "    unique_labels = []\n",
    "    images_ordered = [None]*10\n",
    "    encoding_list_ordered = [None]*10\n",
    "    test_image = images[0]\n",
    "    test_label = labels[0].item()\n",
    "    for i in range(1, subset_size):\n",
    "      if(labels[i].item() not in unique_labels):\n",
    "        unique_labels.append(labels[i].item())\n",
    "        dist = cosine_similarity(encodings[0], encodings[i])\n",
    "        encoding_list_ordered[labels[i].item()] = dist.item()\n",
    "        images_ordered[labels[i].item()] = images[i]\n",
    "    tensor_images = torch.cat(images_ordered, dim=0)\n",
    "    generate_encoding_graph(test_image, test_label, tensor_images, encoding_list_ordered, epoch+1)   \n",
    "  \n",
    "  "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}